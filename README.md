# VGG16-based-Sound-Classification
VGG-16 based sound Classification

Abstract

Hand Gesture recognition has an important place in human machine interactions (HMI). Gestures offer natural means of non-verbal communication. Hand gesture recognition offers vast modelling and creative design prospects as there are many gestures that can be done only with one hand which makes it perfect for controlling smart IoT (internet of things) devices. IoT devices find uses in a wide number of settings, ranging from simple household objects to industrial machines. Considering the growth in the home automation market and the ubiquitous need for interacting with domestic IoT devices,  we propose audio-based surface gestures as a way of interaction and control. In this project we combined sound and hand gestures and proposed a classification model for hand gesture recognition to be used in a smart home setting. We examined microphone technologies based on micro electronic mechanical systems (MEMS), electret modules and piezo disks to identify the best means -- in terms of cost, complexity and accuracy -- of acquiring sound from solid surfaces. To use piezo disks properly, we studied their frequency characteristics and impedance matching circuitry, designed an optimal surface microphone using Atrium, and printed the design into a printed circuit board (PCB).
Our detailed frequency and spectral analysis shows that a piezo-based approach strikes the best performance. We used this setup to train gesture classifiers using modern machine learning models. More specifically, we first constructed a database of audio clips using our setup, and used transfer learning with  a pre-trained convolutional neural network (VGG16). A classification accuracy of %99 was reached with 336 training and 83 test samples.
